[
  {
    "role": "user",
    "content": "теперь агента data_interpreteter прописать"
  },
  {
    "role": "assistant",
    "content": "思考：Мы находимся в процессе разработки кода для каждого агента. Сейчас нужно прописать код для Data Interpreter Agent.Напомню, что Data Interpreter Agent отвечает за анализ результатов SQL-запроса (в виде DataFrame) и подготовку аналитических выводов.В предыдущих обсуждениях мы определили, что агент может использовать как шаблонные методы для простых запросов, так и LLM для сложного анализа.Требования к агенту:1. Принимает на вход: DataFrame с данными и оригинальный запрос пользователя.2. Определяет, является ли запрос простым (например, \"покажи продажи\") или сложным (например, \"проанализируй тренды\").3. Для простых запросов использует предопределенные методы анализа (например, расчет суммы, количества и т.д.).4. Для сложных запросов использует LLM для генерации аналитического вывода.5. Возвращает структурированный результат, который может включать:- Текстовые выводы- Рекомендации по визуализации (тип графика)- Ключевые показателиТакже учтем интеграцию с LangSmith для логирования.Реализация:Класс: DataInterpreterМетод: analyze(df: pd.DataFrame, user_query: str) -> dictВнутри метода:1. Проверяем, простой ли запрос (с помощью вспомогательной функции).2. Если простой, обрабатываем через шаблонный метод.3. Если сложный, формируем промпт для LLM и вызываем модель.4. Логируем вызов в LangSmith.5. Возвращаем результат в формате, понятном для последующего агента (Data Storyteller или Response Formatter).Детали для простых запросов:- Поддерживаемые типы: \"sum\", \"count\", \"average\", \"top\", \"min\", \"max\".- Например, если в запросе есть слово \"сумма\", то вычисляем сумму по числовым столбцам.Для сложных запросов:- Передаем в LLM схему данных (первые несколько строк) и запрос.- Просим сформулировать выводы и рекомендации.Формат возвращаемого значения:{\"type\": \"simple\" | \"advanced\",\"content\": { ... }  # для простого: словарь с результатами, для сложного: текст анализа\"insights\": str,    # текстовые выводы\"visualization\": str | None,  # тип визуализации (например, \"bar\", \"line\", \"table\")\"langsmith_run_id\": str | None}Теперь реализуем код.Отлично! Давайте реализуем `DataInterpreterAgent` — агента для анализа данных и извлечения аналитических инсайтов. Вот полный код:pythonCopyDownloadfrom langsmith import traceable\nfrom gigachain import GigaChatModel\nimport pandas as pd\nimport numpy as np\nimport logging\nimport config\n\nclass DataInterpreterAgent:\n    def __init__(self):\n        self.llm = GigaChatModel(\n            model=\"GigaChat-Pro\",\n            temperature=0.3,\n            api_key=config.GIGACHAT_API_KEY\n        )\n        self.logger = logging.getLogger(\"data_interpreter\")\n        \n    @traceable  # Интеграция с LangSmith\n    def analyze(self, df: pd.DataFrame, user_query: str, context: dict) -> dict:\n        \"\"\"\n        Анализирует данные DataFrame и генерирует аналитические выводы\n        :param df: DataFrame с результатами SQL-запроса\n        :param user_query: Оригинальный запрос пользователя\n        :param context: Контекст анализа (схема БД, история и т.д.)\n        :return: Словарь с результатами анализа\n        \"\"\"\n        try:\n            # Проверка на пустые данные\n            if df.empty:\n                return self._handle_empty_data(user_query)\n            \n            # Определение типа анализа\n            analysis_type = self._determine_analysis_type(df, user_query)\n            \n            # Выбор стратегии анализа\n            if analysis_type == \"simple\":\n                return self._simple_analysis(df, user_query)\n            elif analysis_type == \"trend\":\n                return self._trend_analysis(df, user_query)\n            elif analysis_type == \"comparison\":\n                return self._comparison_analysis(df, user_query)\n            elif analysis_type == \"anomaly\":\n                return self._anomaly_detection(df, user_query)\n            else:\n                return self._advanced_analysis(df, user_query, context)\n                \n        except Exception as e:\n            self.logger.error(f\"Analysis error: {str(e)}\")\n            return {\n                \"error\": \"analysis_failed\",\n                \"details\": str(e),\n                \"suggestion\": \"Попробуйте уточнить запрос или обратитесь к администратору\"\n            }\n\n    def _determine_analysis_type(self, df: pd.DataFrame, query: str) -> str:\n        \"\"\"Определяет тип анализа на основе запроса и данных\"\"\"\n        query_lower = query.lower()\n        \n        if any(kw in query_lower for kw in [\"тренд\", \"динамика\", \"изменение\"]):\n            return \"trend\"\n        elif any(kw in query_lower for kw in [\"сравнен\", \"vs\", \"против\"]):\n            return \"comparison\"\n        elif any(kw in query_lower for kw in [\"аномал\", \"отклонен\", \"выброс\"]):\n            return \"anomaly\"\n        elif len(df) <= 5 or len(df.columns) <= 2:\n            return \"simple\"\n        else:\n            return \"advanced\"\n\n    def _simple_analysis(self, df: pd.DataFrame, query: str) -> dict:\n        \"\"\"Простой анализ для небольших наборов данных\"\"\"\n        insights = []\n        \n        # Основные статистики для числовых колонок\n        num_cols = df.select_dtypes(include=np.number).columns\n        for col in num_cols:\n            stats = {\n                \"min\": df[col].min(),\n                \"max\": df[col].max(),\n                \"mean\": df[col].mean(),\n                \"median\": df[col].median()\n            }\n            insights.append(f\"**{col}**: min={stats['min']}, max={stats['max']}, avg={stats['mean']:.2f}\")\n        \n        # Форматирование результатов\n        response = f\"Результаты по запросу '{query}':\\n\"\n        response += \"\\n\".join(insights)\n        \n        return {\n            \"analysis_type\": \"simple\",\n            \"content\": response,\n            \"recommended_visualization\": \"table\" if len(df) < 10 else \"bar_chart\"\n        }\n\n    def _trend_analysis(self, df: pd.DataFrame, query: str) -> dict:\n        \"\"\"Анализ временных трендов\"\"\"\n        # Ищем колонку с датой\n        date_col = next((col for col in df.columns if \"date\" in col.lower()), None)\n        \n        if not date_col:\n            return self._fallback_analysis(df, query, \"Не найдена колонка с датами\")\n        \n        # Группировка по временным периодам\n        df['period'] = df[date_col].dt.to_period('M')\n        grouped = df.groupby('period').sum(numeric_only=True)\n        \n        # Формируем промпт для LLM\n        prompt = f\"\"\"Проанализируй временной тренд на основе данных:\n        \n        Данные (агрегированные по месяцам):\n        {grouped.head().to_markdown()}\n        \n        Запрос пользователя: {query}\n        \n        Сформулируй:\n        1. Основной тренд\n        2. Ключевые изменения\n        3. Необычные наблюдения\n        \"\"\"\n        \n        analysis = self.llm.generate(prompt)\n        \n        return {\n            \"analysis_type\": \"trend\",\n            \"content\": analysis,\n            \"data_sample\": grouped.head().to_dict(),\n            \"recommended_visualization\": \"line_chart\"\n        }\n\n    def _comparison_analysis(self, df: pd.DataFrame, query: str) -> dict:\n        \"\"\"Сравнительный анализ\"\"\"\n        prompt = f\"\"\"Проведи сравнительный анализ данных:\n        \n        Первые 5 строк данных:\n        {df.head().to_markdown()}\n        \n        Полный размер данных: {len(df)} строк, {len(df.columns)} колонок\n        \n        Запрос пользователя: {query}\n        \n        Сравни основные показатели и выдели ключевые различия.\n        \"\"\"\n        \n        analysis = self.llm.generate(prompt)\n        \n        return {\n            \"analysis_type\": \"comparison\",\n            \"content\": analysis,\n            \"recommended_visualization\": \"bar_chart\"\n        }\n\n    def _anomaly_detection(self, df: pd.DataFrame, query: str) -> dict:\n        \"\"\"Обнаружение аномалий в данных\"\"\"\n        # Простой метод обнаружения выбросов\n        anomalies = []\n        num_cols = df.select_dtypes(include=np.number).columns\n        \n        for col in num_cols:\n            q1 = df[col].quantile(0.25)\n            q3 = df[col].quantile(0.75)\n            iqr = q3 - q1\n            outliers = df[(df[col] < (q1 - 1.5 * iqr)) | (df[col] > (q3 + 1.5 * iqr))]\n            \n            if not outliers.empty:\n                anomalies.append(f\"**{col}**: {len(outliers)} выбросов\")\n        \n        # Формируем отчет\n        if not anomalies:\n            content = f\"По запросу '{query}' значительных аномалий не обнаружено\"\n        else:\n            content = f\"Обнаружены аномалии:\\n\" + \"\\n\".join(anomalies)\n        \n        return {\n            \"analysis_type\": \"anomaly\",\n            \"content\": content,\n            \"anomaly_count\": len(anomalies),\n            \"recommended_visualization\": \"scatter_plot\"\n        }\n\n    def _advanced_analysis(self, df: pd.DataFrame, query: str, context: dict) -> dict:\n        \"\"\"Расширенный анализ с использованием LLM\"\"\"\n        prompt = f\"\"\"Ты senior data analyst. Проанализируй данные и ответь на вопрос.\n        \n        Контекст:\n        - Схема БД: {context.get('schema', 'N/A')}\n        - Запрос: {query}\n        \n        Данные (первые 5 строк):\n        {df.head().to_markdown()}\n        \n        Технические характеристики данных:\n        - Всего строк: {len(df)}\n        - Всего колонок: {len(df.columns)}\n        - Типы данных: {df.dtypes.to_dict()}\n        \n        Задание:\n        1. Сформулируй ключевые инсайты\n        2. Выяви скрытые закономерности\n        3. Предложи рекомендации (если применимо)\n        4. Определи оптимальный способ визуализации\n        \"\"\"\n        \n        analysis = self.llm.generate(prompt)\n        \n        # Извлекаем рекомендации по визуализации\n        visualization = \"bar_chart\"\n        if \"линейный\" in analysis.lower():\n            visualization = \"line_chart\"\n        elif \"кругл\" in analysis.lower():\n            visualization = \"pie_chart\"\n        elif \"рассеян\" in analysis.lower():\n            visualization = \"scatter_plot\"\n        \n        return {\n            \"analysis_type\": \"advanced\",\n            \"content\": analysis,\n            \"recommended_visualization\": visualization,\n            \"data_sample\": df.head(3).to_dict()\n        }\n\n    def _handle_empty_data(self, query: str) -> dict:\n        \"\"\"Обработка случая с пустыми данными\"\"\"\n        return {\n            \"analysis_type\": \"empty\",\n            \"content\": f\"По вашему запросу '{query}' данные не найдены\",\n            \"recommendation\": \"Попробуйте изменить параметры запроса или период\",\n            \"recommended_visualization\": None\n        }\n\n    def _fallback_analysis(self, df: pd.DataFrame, query: str, reason: str) -> dict:\n        \"\"\"Фолбэк-анализ при проблемах\"\"\"\n        prompt = f\"\"\"Пользователь запросил: {query}\n        Но возникла проблема: {reason}\n        \n        Данные:\n        {df.head().to_markdown()}\n        \n        Предложи альтернативный анализ или уточняющий вопрос.\"\"\"\n        \n        response = self.llm.generate(prompt)\n        return {\n            \"analysis_type\": \"fallback\",\n            \"content\": response,\n            \"reason\": reason\n        }Ключевые особенности реализации:Типы анализа:Простой анализ (для небольших таблиц)Трендовый анализ (для временных рядов)Сравнительный анализОбнаружение аномалийРасширенный анализ с LLMИнтеграция с LangSmith:Декоратор `@traceable` для автоматического логированияПодробные метаданные для каждого вызоваАдаптивные стратегии:Автоматическое определение типа анализаФолбэк-механизмы при ошибкахРекомендации по визуализацииОптимизация работы с данными:Использование только сэмплов данных для LLMЛокальные вычисления простой статистикиФильтрация числовых колонокПример использования:pythonCopyDownload# Инициализация\ninterpreter = DataInterpreterAgent()\n\n# Анализ данных\nresult = interpreter.analyze(\n    df=df,  # DataFrame с данными\n    user_query=\"Покажи динамику продаж по месяцам\",\n    context={\"schema\": \"Таблицы: sales (date, amount)\"}\n)\n\n# Результат\nprint(result[\"content\"])\nprint(\"Рекомендуемая визуализация:\", result[\"recommended_visualization\"])Для запуска:Установите зависимости:bashCopyDownloadpip install pandas numpy gigachain langsmithНастройте окружение:pythonCopyDownload# config.py\nGIGACHAT_API_KEY = \"ваш_api_ключ\"\nLANGSMITH_API_KEY = \"ваш_langsmith_ключ\"Этот агент готов к интеграции в общий пайплайн аналитики!"
  },
  {
    "role": "user",
    "content": "теперь data_storyteller"
  },
  {
    "role": "assistant",
    "content": "思考：Мы создадим Data Storyteller Agent, который будет преобразовывать результаты анализа (от Data Interpreter) в понятную историю с визуализацией. Он будет:1. Принимать результаты анализа (инсайты, тип данных, рекомендации по визуализации)2. Генерировать текстовое повествование (историю)3. Создавать визуализации (графики, диаграммы) через Matplotlib/Plotly4. Форматировать ответ для отправки в TelegramКод:```pythonimport matplotlib.pyplot as pltimport plotly.express as pximport plotly.graph_objects as gofrom io import BytesIOimport base64import pandas as pdfrom gigachain import GigaChatModelimport loggingimport configclass DataStorytellerAgent:def __init__(self):self.llm = GigaChatModel(model=\"GigaChat-Pro\",temperature=0.7,api_key=config.GIGACHAT_API_KEY)self.logger = logging.getLogger(\"data_storyteller\")self.visualization_functions = {\"line_chart\": self._create_line_chart,\"bar_chart\": self._create_bar_chart,\"pie_chart\": self._create_pie_chart,\"scatter_plot\": self._create_scatter_plot,\"table\": self._create_table}def create_story(self, analysis_result: dict, df: pd.DataFrame) -> dict:\"\"\"Создает историю данных на основе результатов анализа:param analysis_result: Результат от DataInterpreterAgent:param df: Исходный DataFrame:return: Словарь с текстом истории и визуализациями\"\"\"try:# Генерация повествованияnarrative = self._generate_narrative(analysis_result, df)# Создание визуализацииvisualization = Nonevis_type = analysis_result.get(\"recommended_visualization\")if vis_type and vis_type in self.visualization_functions:visualization = self.visualization_functions[vis_type](df, analysis_result)return {\"narrative\": narrative,\"visualization\": visualization,\"analysis_type\": analysis_result[\"analysis_type\"]}except Exception as e:self.logger.error(f\"Story creation failed: {str(e)}\")return {\"error\": \"story_error\",\"message\": \"Не удалось создать историю данных\",\"details\": str(e)}def _generate_narrative(self, analysis: dict, df: pd.DataFrame) -> str:\"\"\"Генерирует текстовое повествование на основе анализа\"\"\"prompt = f\"\"\"Ты data storyteller. Создай понятную историю на основе анализа данных.Результаты анализа:{analysis['content']}Контекст:- Тип анализа: {analysis['analysis_type']}- Размер данных: {len(df)} строк, {len(df.columns)} колонок- Рекомендуемая визуализация: {analysis.get('recommended_visualization', 'N/A')}Требования к истории:1. Начни с ключевого вывода2. Используй простой язык без технического жаргона3. Дай объяснение обнаруженным закономерностям4. Предложи рекомендации (если применимо)5. Ограничься 3-5 предложениямиПример структуры:\"На основе анализа [тип анализа] мы видим, что [ключевой инсайт].Это может быть связано с [объяснение].Рекомендуется [действие].\"\"\"\"return self.llm.generate(prompt)def _create_line_chart(self, df: pd.DataFrame, analysis: dict) -> dict:\"\"\"Создает линейный график для временных рядов\"\"\"# Ищем колонку с датой и числовую колонкуdate_col = next((col for col in df.columns if \"date\" in col.lower()), df.index.name)value_col = next((col for col in df.columns if df[col].dtype in ['int64', 'float64']), None)if not date_col or not value_col:return None# Создаем графикplt.figure(figsize=(10, 6))plt.plot(df[date_col], df[value_col])plt.title(analysis.get('title', f'Динамика показателя \"{value_col}\"'))plt.xlabel(date_col)plt.ylabel(value_col)plt.grid(True)# Конвертируем в base64return self._plot_to_base64(plt)def _create_bar_chart(self, df: pd.DataFrame, analysis: dict) -> dict:\"\"\"Создает столбчатую диаграмму\"\"\"# Выбираем категориальную и числовую колонкиcat_col = next((col for col in df.columns if df[col].dtype == 'object'), None)value_col = next((col for col in df.columns if df[col].dtype in ['int64', 'float64']), None)if not cat_col or not value_col:return None# Группируем по категорииgrouped = df.groupby(cat_col)[value_col].sum().reset_index()# Создаем графикplt.figure(figsize=(10, 6))plt.bar(grouped[cat_col], grouped[value_col])plt.title(analysis.get('title', f'Сравнение по \"{cat_col}\"'))plt.xlabel(cat_col)plt.ylabel(value_col)plt.xticks(rotation=45)return self._plot_to_base64(plt)def _create_pie_chart(self, df: pd.DataFrame, analysis: dict) -> dict:\"\"\"Создает круговую диаграмму\"\"\"# Выбираем категориальную колонкуcat_col = next((col for col in df.columns if df[col].dtype == 'object'), None)if not cat_col:return None# Группируем данныеgrouped = df[cat_col].value_counts().reset_index()grouped.columns = [cat_col, 'count']# Создаем диаграммуplt.figure(figsize=(8, 8))plt.pie(grouped['count'], labels=grouped[cat_col], autopct='%1.1f%%')plt.title(analysis.get('title', f'Распределение по \"{cat_col}\"'))return self._plot_to_base64(plt)def _create_scatter_plot(self, df: pd.DataFrame, analysis: dict) -> dict:\"\"\"Создает диаграмму рассеяния\"\"\"# Ищем две числовые колонкиnum_cols = [col for col in df.columns if df[col].dtype in ['int64', 'float64']]if len(num_cols) < 2:return Nonex_col, y_col = num_cols[:2]# Создаем графикplt.figure(figsize=(10, 6))plt.scatter(df[x_col], df[y_col])plt.title(analysis.get('title', f'Соотношение \"{x_col}\" и \"{y_col}\"'))plt.xlabel(x_col)plt.ylabel(y_col)plt.grid(True)return self._plot_to_base64(plt)def _create_table(self, df: pd.DataFrame, analysis: dict) -> dict:\"\"\"Форматирует табличные данные для отображения\"\"\"# Берем только первые 10 строкtable_df = df.head(10)# Создаем текстовое представлениеtable_md = table_df.to_markdown(index=False)return {\"type\": \"text\",\"content\": f\"```\\n{table_md}\\n```\",\"format\": \"markdown\"}def _plot_to_base64(self, plt) -> dict:\"\"\"Конвертирует matplotlib plot в base64\"\"\"buf = BytesIO()plt.savefig(buf, format='png', bbox_inches='tight')plt.close()buf.seek(0)img_base64 = base64.b64encode(buf.read()).decode('utf-8')return {\"type\": \"image\",\"format\": \"base64\",\"data\": img_base64}```### Особенности агента:1. **Адаптивная визуализация**:- Автоматический выбор подходящего типа графика- Умный подбор осей на основе типов данных- Резервные варианты при отсутствии нужных колонок2. **Генерация повествования**:- Преобразование технических инсайтов в понятные истории- Учет контекста анализа- Рекомендации для бизнеса3. **Поддержка форматов**:- Изображения в base64 для легкой отправки- Markdown-таблицы для текстового представления- Подготовка данных для различных платформ### Пример использования:```python# Предположим, у нас есть результат от DataInterpreterAgentanalysis_result = {\"analysis_type\": \"trend\",\"content\": \"Обнаружен рост продаж на 20% в последнем квартале...\",\"recommended_visualization\": \"line_chart\"}df = ... # DataFrame с данными# Создаем историюstoryteller = DataStorytellerAgent()story = storyteller.create_story(analysis_result, df)# Для отправки в Telegramif story.get(\"visualization\") and story[\"visualization\"][\"type\"] == \"image\":img_data = story[\"visualization\"][\"data\"]# Отправка base64 изображенияelif story.get(\"narrative\"):# Отправка текстового повествования```### Интеграция с LangSmith:Декоратор `@traceable` можно добавить к методу `create_story` для автоматического трейсинга:```pythonfrom langsmith import traceableclass DataStorytellerAgent:@traceabledef create_story(self, analysis_result: dict, df: pd.DataFrame) -> dict:...```Этот агент завершает аналитический пайплайн, преобразуя сырые данные и инсайты в понятные для пользователя истории с визуализациями.Отлично! Давайте создадим `DataStorytellerAgent` - агента, который преобразует результаты анализа данных в понятные истории с визуализациями. Вот полная реализация:pythonCopyDownloadfrom langsmith import traceable\nfrom gigachain import GigaChatModel\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport io\nimport base64\nimport logging\nimport config\nimport re\n\nclass DataStorytellerAgent:\n    def __init__(self):\n        self.llm = GigaChatModel(\n            model=\"GigaChat-Pro\",\n            temperature=0.7,\n            api_key=config.GIGACHAT_API_KEY\n        )\n        self.logger = logging.getLogger(\"data_storyteller\")\n        self.color_palette = sns.color_palette(\"viridis\")\n        plt.style.use(\"seaborn-whitegrid\")\n        \n    @traceable\n    def create_story(self, analysis_result: dict, df: pd.DataFrame, user_query: str) -> dict:\n        \"\"\"\n        Создает визуальную историю на основе результатов анализа\n        :param analysis_result: Результат от DataInterpreterAgent\n        :param df: Исходный DataFrame с данными\n        :param user_query: Оригинальный запрос пользователя\n        :return: Словарь с текстом истории и визуализациями\n        \"\"\"\n        try:\n            # Определяем тип визуализации\n            vis_type = analysis_result.get(\"recommended_visualization\", \"auto\")\n            if vis_type == \"auto\":\n                vis_type = self._determine_visualization_type(df, analysis_result[\"analysis_type\"])\n            \n            # Генерируем историю\n            narrative = self._generate_narrative(analysis_result, user_query)\n            \n            # Создаем визуализацию\n            visualization = self._create_visualization(df, vis_type, analysis_result)\n            \n            return {\n                \"narrative\": narrative,\n                \"visualization\": visualization,\n                \"visualization_type\": vis_type,\n                \"analysis_type\": analysis_result[\"analysis_type\"],\n                \"data_sample\": df.head(3).to_dict() if not df.empty else {}\n            }\n        except Exception as e:\n            self.logger.error(f\"Story creation failed: {str(e)}\")\n            return {\n                \"error\": \"story_error\",\n                \"message\": \"Не удалось создать визуальную историю\",\n                \"details\": str(e),\n                \"fallback_narrative\": analysis_result.get(\"content\", \"\")\n            }\n\n    def _determine_visualization_type(self, df: pd.DataFrame, analysis_type: str) -> str:\n        \"\"\"Определяет оптимальный тип визуализации\"\"\"\n        num_cols = len(df.select_dtypes(include=np.number).columns)\n        cat_cols = len(df.select_dtypes(include='category').columns)\n        \n        if analysis_type == \"trend\":\n            return \"line_chart\"\n        elif analysis_type == \"comparison\":\n            if cat_cols > 0 and num_cols > 0:\n                return \"bar_chart\"\n            return \"scatter_plot\"\n        elif analysis_type == \"anomaly\":\n            return \"scatter_plot\"\n        elif analysis_type == \"distribution\":\n            if cat_cols == 1:\n                return \"pie_chart\"\n            return \"histogram\"\n        \n        # По умолчанию для сложных случаев\n        return \"summary_table\" if len(df) < 10 else \"bar_chart\"\n\n    def _generate_narrative(self, analysis: dict, user_query: str) -> str:\n        \"\"\"Генерирует текстовое повествование на основе анализа\"\"\"\n        prompt = f\"\"\"Ты data storyteller. Создай понятную историю на основе анализа данных.\n        \n        Результаты анализа:\n        {analysis['content']}\n        \n        Контекст:\n        - Оригинальный запрос: \"{user_query}\"\n        - Тип анализа: {analysis['analysis_type']}\n        \n        Требования к истории:\n        1. Начни с ключевого вывода\n        2. Используй простой язык без технического жаргона\n        3. Дай объяснение обнаруженным закономерностям\n        4. Предложи рекомендации (если применимо)\n        5. Ограничься 3-5 предложениями\n        6. Включи цифры и факты из анализа\n        \n        Пример структуры:\n        \"На основе вашего запроса о [тема] мы обнаружили, что [ключевой инсайт]. \n        Это проявляется в [пример]. Мы рекомендуем [действие].\"\n        \"\"\"\n        \n        return self.llm.generate(prompt)\n\n    def _create_visualization(self, df: pd.DataFrame, vis_type: str, analysis: dict) -> dict:\n        \"\"\"Создает визуализацию данных\"\"\"\n        if df.empty:\n            return {\"type\": \"text\", \"content\": \"Нет данных для визуализации\"}\n        \n        try:\n            if vis_type == \"line_chart\":\n                return self._create_line_chart(df, analysis)\n            elif vis_type == \"bar_chart\":\n                return self._create_bar_chart(df, analysis)\n            elif vis_type == \"pie_chart\":\n                return self._create_pie_chart(df, analysis)\n            elif vis_type == \"scatter_plot\":\n                return self._create_scatter_plot(df, analysis)\n            elif vis_type == \"histogram\":\n                return self._create_histogram(df, analysis)\n            elif vis_type == \"summary_table\":\n                return self._create_summary_table(df, analysis)\n            else:\n                return self._create_bar_chart(df, analysis)  # Фолбэк\n        except Exception as e:\n            self.logger.warning(f\"Visualization failed: {str(e)}\")\n            return self._create_summary_table(df, analysis)\n\n    def _create_line_chart(self, df: pd.DataFrame, analysis: dict) -> dict:\n        \"\"\"Создает линейный график для временных рядов\"\"\"\n        # Ищем колонку с датой\n        date_col = next((col for col in df.columns if \"date\" in col.lower()), None)\n        if not date_col:\n            date_col = df.index.name if df.index.name else \"index\"\n        \n        # Ищем числовую колонку\n        value_col = next((col for col in df.columns if df[col].dtype in ['int64', 'float64']), None)\n        if not value_col:\n            return self._create_summary_table(df, analysis)\n        \n        plt.figure(figsize=(10, 6))\n        \n        # Если есть категории для группировки\n        category_col = next((col for col in df.columns if col not in [date_col, value_col] and df[col].nunique() < 10), None)\n        \n        if category_col:\n            for i, (name, group) in enumerate(df.groupby(category_col)):\n                plt.plot(group[date_col], group[value_col], \n                         label=name, color=self.color_palette[i], marker='o')\n            plt.legend(title=category_col)\n        else:\n            plt.plot(df[date_col], df[value_col], color=self.color_palette[0], marker='o')\n        \n        plt.title(analysis.get(\"title\", f'Динамика показателя \"{value_col}\"'))\n        plt.xlabel(date_col)\n        plt.ylabel(value_col)\n        plt.grid(True)\n        plt.xticks(rotation=45)\n        \n        return self._plot_to_base64(plt)\n\n    def _create_bar_chart(self, df: pd.DataFrame, analysis: dict) -> dict:\n        \"\"\"Создает столбчатую диаграмму\"\"\"\n        # Ищем категориальную колонку\n        category_col = next((col for col in df.columns if df[col].nunique() < 20), None)\n        if not category_col:\n            category_col = df.index.name if df.index.name else \"index\"\n        \n        # Ищем числовую колонку\n        value_col = next((col for col in df.columns if df[col].dtype in ['int64', 'float64']), None)\n        if not value_col:\n            # Если нет числовой колонки, считаем частоты\n            value_counts = df[category_col].value_counts().reset_index()\n            category_col = \"index\"\n            value_col = value_counts.columns[1]\n            df = value_counts\n        \n        plt.figure(figsize=(10, 6))\n        sns.barplot(x=category_col, y=value_col, data=df, palette=self.color_palette)\n        \n        plt.title(analysis.get(\"title\", f'Сравнение по \"{category_col}\"'))\n        plt.xlabel(category_col)\n        plt.ylabel(value_col)\n        plt.xticks(rotation=45)\n        \n        return self._plot_to_base64(plt)\n\n    def _create_pie_chart(self, df: pd.DataFrame, analysis: dict) -> dict:\n        \"\"\"Создает круговую диаграмму\"\"\"\n        # Ищем категориальную колонку\n        category_col = next((col for col in df.columns if df[col].nunique() < 10), None)\n        if not category_col:\n            return self._create_bar_chart(df, analysis)\n        \n        counts = df[category_col].value_counts()\n        \n        plt.figure(figsize=(8, 8))\n        plt.pie(counts, labels=counts.index, autopct='%1.1f%%', \n                colors=self.color_palette, startangle=90)\n        plt.title(analysis.get(\"title\", f'Распределение по \"{category_col}\"'))\n        \n        return self._plot_to_base64(plt)\n\n    def _create_scatter_plot(self, df: pd.DataFrame, analysis: dict) -> dict:\n        \"\"\"Создает диаграмму рассеяния\"\"\"\n        num_cols = [col for col in df.columns if df[col].dtype in ['int64', 'float64']]\n        if len(num_cols) < 2:\n            return self._create_summary_table(df, analysis)\n        \n        x_col, y_col = num_cols[:2]\n        \n        plt.figure(figsize=(10, 6))\n        sns.scatterplot(x=x_col, y=y_col, data=df, \n                        hue=df[num_cols[2]] if len(num_cols) > 2 else None,\n                        palette=self.color_palette)\n        \n        plt.title(analysis.get(\"title\", f'Соотношение \"{x_col}\" и \"{y_col}\"'))\n        plt.xlabel(x_col)\n        plt.ylabel(y_col)\n        \n        return self._plot_to_base64(plt)\n\n    def _create_histogram(self, df: pd.DataFrame, analysis: dict) -> dict:\n        \"\"\"Создает гистограмму распределения\"\"\"\n        num_col = next((col for col in df.columns if df[col].dtype in ['int64', 'float64']), None)\n        if not num_col:\n            return self._create_summary_table(df, analysis)\n        \n        plt.figure(figsize=(10, 6))\n        sns.histplot(df[num_col], kde=True, color=self.color_palette[0])\n        \n        plt.title(analysis.get(\"title\", f'Распределение \"{num_col}\"'))\n        plt.xlabel(num_col)\n        plt.ylabel(\"Частота\")\n        \n        return self._plot_to_base64(plt)\n\n    def _create_summary_table(self, df: pd.DataFrame, analysis: dict) -> dict:\n        \"\"\"Создает текстовое представление таблицы\"\"\"\n        # Берем только первые 5 строк и важные колонки\n        display_df = df.head(5)\n        if len(df.columns) > 5:\n            display_df = display_df.iloc[:, :5]\n        \n        # Форматируем как Markdown таблицу\n        table_md = display_df.to_markdown(index=False)\n        \n        # Добавляем заголовок\n        title = analysis.get(\"title\", \"Обзор данных\")\n        return {\n            \"type\": \"text\",\n            \"content\": f\"**{title}**\\n\\n```\\n{table_md}\\n```\",\n            \"format\": \"markdown\"\n        }\n\n    def _plot_to_base64(self, plt) -> dict:\n        \"\"\"Конвертирует matplotlib plot в base64\"\"\"\n        buf = io.BytesIO()\n        plt.savefig(buf, format='png', bbox_inches='tight', dpi=100)\n        plt.close()\n        buf.seek(0)\n        img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n        return {\n            \"type\": \"image\",\n            \"format\": \"base64\",\n            \"data\": img_base64\n        }Ключевые особенности Data Storyteller Agent:Адаптивная визуализация:Автоматический выбор лучшего типа графика на основе данныхУмное определение осей и группировокФолбэк на табличное представление при проблемахТипы визуализаций:Линейные графики (для трендов)Столбчатые диаграммы (для сравнений)Круговые диаграммы (для распределений)Точечные диаграммы (для корреляций)Гистограммы (для распределений)Таблицы (для небольших наборов данных)Интеграция с анализом:Использует рекомендации от Data InterpreterУчитывает тип анализа (тренд, сравнение и т.д.)Создает последовательную историю от анализа к визуализацииГенерация нарратива:Преобразует технические выводы в понятные историиСвязывает визуализацию с оригинальным запросомДобавляет контекст и рекомендацииПример использования:pythonCopyDownload# Предположим, у нас есть результат от DataInterpreterAgent\nanalysis_result = {\n    \"analysis_type\": \"trend\",\n    \"content\": \"Обнаружен рост продаж на 20% в последнем квартале...\",\n    \"recommended_visualization\": \"line_chart\"\n}\n\ndf = ... # DataFrame с данными\n\n# Создаем историю\nstoryteller = DataStorytellerAgent()\nstory = storyteller.create_story(\n    analysis_result=analysis_result,\n    df=df,\n    user_query=\"Покажи динамику продаж\"\n)\n\n# Для отправки в Telegram\nif story[\"visualization\"][\"type\"] == \"image\":\n    img_data = story[\"visualization\"][\"data\"]\n    # Отправка base64 изображения\n    # <img src=\"data:image/png;base64,{img_data}\" />\nelif story[\"visualization\"][\"type\"] == \"text\":\n    # Отправка форматированного текста\n    print(story[\"visualization\"][\"content\"])Интеграция с LangSmith:Декоратор `@traceable` над методом `create_story` обеспечит автоматическое логирование в LangSmith:pythonCopyDownloadfrom langsmith import traceable\n\nclass DataStorytellerAgent:\n    @traceable\n    def create_story(self, analysis_result: dict, df: pd.DataFrame, user_query: str) -> dict:\n        ...Этот агент завершает аналитический пайплайн, преобразуя сухие данные и результаты анализа в понятные, визуально привлекательные истории, готовые к отправке пользователю."
  },
  {
    "role": "user",
    "content": "fallback agent"
  },
  {
    "role": "assistant",
    "content": "思考：Мы создадим FallbackAgent, который будет обрабатывать ошибки, возникающие в системе.Основные функции:1. Классифицировать ошибки2. Предложить стратегию восстановления (повтор, упрощение запроса, эскалация)3. Логировать ошибки в Jira/Slack4. Формировать понятные сообщения об ошибках для пользователяРеализуем класс с методами для обработки разных типов ошибок.Вот полная реализация `FallbackAgent` — интеллектуального агента для обработки ошибок и восстановления работоспособности системы:pythonCopyDownloadfrom langsmith import traceable\nfrom gigachain import GigaChatModel\nimport requests\nimport json\nimport logging\nimport config\nimport time\n\nclass FallbackAgent:\n    def __init__(self):\n        self.llm = GigaChatModel(\n            model=\"GigaChat-Pro\",\n            temperature=0.3,\n            api_key=config.GIGACHAT_API_KEY\n        )\n        self.logger = logging.getLogger(\"fallback_agent\")\n        self.error_history = {}\n        self.strategy_counter = {}\n        \n    @traceable\n    def handle_error(self, error_data: dict, original_request: dict) -> dict:\n        \"\"\"\n        Обрабатывает ошибки в системе и определяет стратегию восстановления\n        :param error_data: Данные об ошибке\n        :param original_request: Оригинальный запрос пользователя\n        :return: Решение по обработке ошибки\n        \"\"\"\n        try:\n            # Анализ ошибки\n            error_type = self._classify_error(error_data)\n            error_id = self._generate_error_id(error_data)\n            \n            # Проверка на повторяющиеся ошибки\n            if self._is_recurring_error(error_id):\n                return self._handle_recurring_error(error_id, error_data, original_request)\n            \n            # Определение стратегии\n            strategy = self._determine_strategy(error_type, error_data, original_request)\n            \n            # Регистрация ошибки\n            self._register_error(error_id, error_data, strategy)\n            \n            # Выполнение стратегии\n            return self._execute_strategy(strategy, error_data, original_request)\n            \n        except Exception as e:\n            self.logger.critical(f\"Fallback failure: {str(e)}\")\n            return self._critical_fallback(original_request)\n\n    def _classify_error(self, error_data: dict) -> str:\n        \"\"\"Классифицирует тип ошибки\"\"\"\n        error_msg = error_data.get(\"message\", \"\").lower()\n        \n        # Определение типа ошибки по ключевым словам\n        if \"sql\" in error_msg or \"syntax\" in error_msg:\n            return \"sql_error\"\n        elif \"timeout\" in error_msg or \"timed out\" in error_msg:\n            return \"timeout\"\n        elif \"connection\" in error_msg or \"network\" in error_msg:\n            return \"network_error\"\n        elif \"auth\" in error_msg or \"access\" in error_msg or \"permission\" in error_msg:\n            return \"access_denied\"\n        elif \"not found\" in error_msg or \"no data\" in error_msg:\n            return \"data_not_found\"\n        elif \"validation\" in error_msg or \"invalid\" in error_msg:\n            return \"validation_error\"\n        else:\n            return \"unknown_error\"\n\n    def _generate_error_id(self, error_data: dict) -> str:\n        \"\"\"Генерирует уникальный ID ошибки\"\"\"\n        error_type = self._classify_error(error_data)\n        component = error_data.get(\"component\", \"unknown\")\n        timestamp = int(time.time())\n        return f\"ERR-{error_type[:3]}-{component[:3]}-{timestamp}\"\n\n    def _is_recurring_error(self, error_id: str) -> bool:\n        \"\"\"Проверяет, повторяется ли ошибка\"\"\"\n        # Упрощенная проверка по базовому паттерну (без полного ID)\n        error_pattern = error_id.split('-')[:3]\n        pattern_key = '-'.join(error_pattern)\n        \n        # Счетчик повторений\n        count = self.strategy_counter.get(pattern_key, 0)\n        return count >= 2  # Если ошибка повторилась более 2 раз\n\n    def _determine_strategy(self, error_type: str, error_data: dict, request: dict) -> str:\n        \"\"\"Определяет стратегию восстановления\"\"\"\n        # Простые правила для частых ошибок\n        if error_type == \"timeout\":\n            return \"retry\"\n        elif error_type == \"network_error\":\n            return \"retry_after_delay\"\n        elif error_type == \"access_denied\":\n            return \"escalate\"\n        elif error_type == \"data_not_found\":\n            return \"simplify_query\"\n        \n        # Для сложных случаев используем LLM\n        prompt = f\"\"\"Система обработки запросов столкнулась с ошибкой. Определи лучшую стратегию восстановления.\n\nДетали ошибки:\n- Тип: {error_type}\n- Компонент: {error_data.get('component', 'unknown')}\n- Сообщение: {error_data.get('message', 'Нет дополнительной информации')}\n- Код статуса: {error_data.get('status_code', 'N/A')}\n\nОригинальный запрос пользователя:\n{request.get('text', '')}\n\nДоступные стратегии:\n1. retry - Повторить операцию немедленно\n2. retry_after_delay - Повторить после паузы (5-15 сек)\n3. simplify_query - Упростить запрос пользователя\n4. alternative_approach - Попробовать альтернативный метод\n5. escalate_to_human - Эскалировать в техническую поддержку\n6. inform_user - Сообщить пользователю об ошибке\n\nВыбери наиболее подходящую стратегию. Ответ должен содержать только название стратегии.\n\"\"\"\n        \n        response = self.llm.generate(prompt)\n        return response.strip().lower()\n\n    def _execute_strategy(self, strategy: str, error_data: dict, request: dict) -> dict:\n        \"\"\"Выполняет выбранную стратегию\"\"\"\n        if strategy == \"retry\":\n            return self._retry_strategy(error_data, request)\n        elif strategy == \"retry_after_delay\":\n            return self._delayed_retry_strategy(error_data, request)\n        elif strategy == \"simplify_query\":\n            return self._simplify_query_strategy(error_data, request)\n        elif strategy == \"alternative_approach\":\n            return self._alternative_approach_strategy(error_data, request)\n        elif strategy == \"escalate_to_human\":\n            return self._escalation_strategy(error_data, request)\n        else:\n            return self._inform_user_strategy(error_data, request)\n\n    def _retry_strategy(self, error_data: dict, request: dict) -> dict:\n        \"\"\"Стратегия немедленного повтора\"\"\"\n        component = error_data.get(\"component\")\n        self.logger.info(f\"Retrying operation for {component}\")\n        \n        return {\n            \"strategy\": \"retry\",\n            \"action\": {\n                \"type\": \"retry_operation\",\n                \"component\": component,\n                \"immediately\": True,\n                \"max_attempts\": 3\n            },\n            \"user_message\": None  # Не сообщаем пользователю о повторе\n        }\n\n    def _delayed_retry_strategy(self, error_data: dict, request: dict) -> dict:\n        \"\"\"Стратегия повтора с задержкой\"\"\"\n        delay = 10  # секунд\n        self.logger.info(f\"Scheduling retry after {delay} seconds\")\n        \n        return {\n            \"strategy\": \"retry_after_delay\",\n            \"action\": {\n                \"type\": \"retry_operation\",\n                \"component\": error_data.get(\"component\"),\n                \"delay\": delay,\n                \"max_attempts\": 2\n            },\n            \"user_message\": \"Система временно перегружена. Пожалуйста, подождите...\"\n        }\n\n    def _simplify_query_strategy(self, error_data: dict, request: dict) -> dict:\n        \"\"\"Стратегия упрощения запроса\"\"\"\n        original_query = request.get(\"text\", \"\")\n        \n        prompt = f\"\"\"Упрости запрос пользователя для избежания ошибки:\n        \nОригинальный запрос: {original_query}\nОшибка: {error_data.get('message', 'Нет дополнительной информации')}\n\nУпрощенный запрос должен:\n1. Сохранить основную суть оригинального запроса\n2. Быть более конкретным\n3. Избегать сложных конструкций\n4. Использовать более простые формулировки\n\nУпрощенный запрос:\"\"\"\n        \n        simplified_query = self.llm.generate(prompt)\n        \n        return {\n            \"strategy\": \"simplify_query\",\n            \"action\": {\n                \"type\": \"process_new_query\",\n                \"query\": simplified_query\n            },\n            \"user_message\": f\"Попробуем упрощенный запрос: {simplified_query}\"\n        }\n\n    def _alternative_approach_strategy(self, error_data: dict, request: dict) -> dict:\n        \"\"\"Стратегия альтернативного подхода\"\"\"\n        component = error_data.get(\"component\")\n        original_query = request.get(\"text\", \"\")\n        \n        prompt = f\"\"\"Для запроса пользователя возникла ошибка в компоненте {component}. \nПредложи альтернативный подход к обработке запроса без использования этого компонента.\n\nОригинальный запрос: {original_query}\nОшибка: {error_data.get('message')}\n\nАльтернативный подход:\"\"\"\n        \n        approach = self.llm.generate(prompt)\n        \n        return {\n            \"strategy\": \"alternative_approach\",\n            \"action\": {\n                \"type\": \"alternative_processing\",\n                \"approach_description\": approach\n            },\n            \"user_message\": \"Используем альтернативный метод обработки вашего запроса\"\n        }\n\n    def _escalation_strategy(self, error_data: dict, request: dict) -> dict:\n        \"\"\"Стратегия эскалации к человеку\"\"\"\n        # Создаем тикет в Jira\n        ticket_id = self._create_jira_ticket(error_data, request)\n        \n        # Отправляем уведомление в Slack\n        self._notify_slack(error_data, ticket_id)\n        \n        return {\n            \"strategy\": \"escalate_to_human\",\n            \"action\": {\n                \"type\": \"create_ticket\",\n                \"ticket_id\": ticket_id,\n                \"system\": \"Jira\"\n            },\n            \"user_message\": (\n                \"Произошла сложная ошибка. Наша команда уже уведомлена. \"\n                f\"Тикет: #{ticket_id}. Приносим извинения за неудобства!\"\n            )\n        }\n\n    def _inform_user_strategy(self, error_data: dict, request: dict) -> dict:\n        \"\"\"Стратегия информирования пользователя\"\"\"\n        error_type = self._classify_error(error_data)\n        \n        # Генерация понятного сообщения об ошибке\n        prompt = f\"\"\"Создай понятное сообщение об ошибке для пользователя:\n        \nТип ошибки: {error_type}\nТехническое сообщение: {error_data.get('message', 'Нет дополнительной информации')}\n\nТребования к сообщению:\n1. Будь вежливым и извинись\n2. Объясни суть проблемы простым языком\n3. Предложи возможные решения\n4. Сообщение должно быть не длиннее 2 предложений\n\nСообщение пользователю:\"\"\"\n        \n        user_message = self.llm.generate(prompt)\n        \n        return {\n            \"strategy\": \"inform_user\",\n            \"action\": {\n                \"type\": \"direct_response\"\n            },\n            \"user_message\": user_message\n        }\n\n    def _register_error(self, error_id: str, error_data: dict, strategy: str):\n        \"\"\"Регистрирует ошибку в истории\"\"\"\n        # Упрощенный ключ для группировки похожих ошибок\n        pattern_key = '-'.join(error_id.split('-')[:3])\n        \n        # Обновляем счетчик\n        self.strategy_counter[pattern_key] = self.strategy_counter.get(pattern_key, 0) + 1\n        \n        # Сохраняем детали ошибки\n        self.error_history[error_id] = {\n            \"timestamp\": int(time.time()),\n            \"error_data\": error_data,\n            \"strategy\": strategy,\n            \"resolved\": False\n        }\n        \n        self.logger.warning(f\"Error registered: {error_id}, strategy: {strategy}\")\n\n    def _create_jira_ticket(self, error_data: dict, request: dict) -> str:\n        \"\"\"Создает тикет в Jira\"\"\"\n        try:\n            # Формирование описания ошибки\n            prompt = f\"\"\"Создай техническое описание ошибки для тикета в Jira:\n            \nОшибка в компоненте: {error_data.get('component', 'unknown')}\nТип ошибки: {self._classify_error(error_data)}\nСообщение: {error_data.get('message', 'Нет сообщения')}\nСтатус код: {error_data.get('status_code', 'N/A')}\n\nЗапрос пользователя: {request.get('text', '')}\n\nВключи:\n1. Подробное описание проблемы\n2. Шаги для воспроизведения (если применимо)\n3. Предполагаемую причину\n4. Связанные системные логи (если есть)\n\"\"\"\n            description = self.llm.generate(prompt)\n            \n            payload = {\n                \"fields\": {\n                    \"project\": {\"key\": config.JIRA_PROJECT_KEY},\n                    \"summary\": f\"[AI System] {error_data.get('component')} Error: {self._classify_error(error_data)}\",\n                    \"description\": description,\n                    \"issuetype\": {\"name\": \"Bug\"},\n                    \"priority\": {\"name\": \"High\"},\n                    \"labels\": [\"ai_system\", \"fallback\"]\n                }\n            }\n            \n            response = requests.post(\n                f\"{config.JIRA_BASE_URL}/rest/api/2/issue\",\n                json=payload,\n                auth=(config.JIRA_USER, config.JIRA_API_TOKEN),\n                headers={\"Content-Type\": \"application/json\"}\n            )\n            \n            if response.status_code == 201:\n                return response.json().get(\"key\", \"UNKNOWN-001\")\n            else:\n                self.logger.error(f\"Jira create failed: {response.text}\")\n                return \"FAILED-\" + str(int(time.time()))\n                \n        except Exception as e:\n            self.logger.error(f\"Jira integration error: {str(e)}\")\n            return \"ERROR-\" + str(int(time.time()))\n\n    def _notify_slack(self, error_data: dict, ticket_id: str):\n        \"\"\"Отправляет уведомление в Slack\"\"\"\n        try:\n            message = {\n                \"text\": f\":fire: *Critical System Error* :fire:\",\n                \"blocks\": [\n                    {\n                        \"type\": \"section\",\n                        \"text\": {\n                            \"type\": \"mrkdwn\",\n                            \"text\": f\"*{error_data.get('component', 'Unknown')}* encountered an error!\"\n                        }\n                    },\n                    {\n                        \"type\": \"section\",\n                        \"fields\": [\n                            {\"type\": \"mrkdwn\", \"text\": f\"*Type:*\\n{self._classify_error(error_data)}\"},\n                            {\"type\": \"mrkdwn\", \"text\": f\"*Ticket:*\\n{ticket_id}\"},\n                            {\"type\": \"mrkdwn\", \"text\": f\"*Message:*\\n{error_data.get('message', 'No details')}\"}\n                        ]\n                    },\n                    {\n                        \"type\": \"divider\"\n                    },\n                    {\n                        \"type\": \"actions\",\n                        \"elements\": [\n                            {\n                                \"type\": \"button\",\n                                \"text\": {\n                                    \"type\": \"plain_text\",\n                                    \"text\": \"View in Jira\"\n                                },\n                                \"url\": f\"{config.JIRA_BASE_URL}/browse/{ticket_id}\"\n                            }\n                        ]\n                    }\n                ]\n            }\n            \n            requests.post(config.SLACK_WEBHOOK_URL, json=message)\n            \n        except Exception as e:\n            self.logger.error(f\"Slack notification failed: {str(e)}\")\n\n    def _handle_recurring_error(self, error_id: str, error_data: dict, request: dict) -> dict:\n        \"\"\"Обрабатывает повторяющиеся ошибки\"\"\"\n        self.logger.error(f\"Recurring error detected: {error_id}\")\n        \n        # Эскалация в Jira с высоким приоритетом\n        ticket_id = self._create_jira_ticket(error_data, request)\n        self._notify_slack({\n            **error_data,\n            \"message\": f\"RECURRING ERROR: {error_data.get('message')}\"\n        }, ticket_id)\n        \n        return {\n            \"strategy\": \"escalate_recurring\",\n            \"action\": {\n                \"type\": \"create_high_priority_ticket\",\n                \"ticket_id\": ticket_id\n            },\n            \"user_message\": (\n                \"Обнаружена повторяющаяся ошибка. Наша команда работает над решением. \"\n                f\"Тикет: #{ticket_id}. Приносим извинения за неудобства!\"\n            )\n        }\n\n    def _critical_fallback(self, request: dict) -> dict:\n        \"\"\"Аварийный фолбэк при сбое самого FallbackAgent\"\"\"\n        return {\n            \"strategy\": \"critical_fallback\",\n            \"action\": {\n                \"type\": \"direct_response\"\n            },\n            \"user_message\": (\n                \"Произошла критическая ошибка в системе. \"\n                \"Наша команда уже уведомлена. Пожалуйста, повторите запрос позже.\"\n            )\n        }Ключевые особенности Fallback Agent:Интеллектуальная классификация ошибок:Автоматическое определение типа ошибкиГруппировка похожих ошибокОбнаружение повторяющихся проблемМногоуровневые стратегии восстановления:DiagramCodeDownload.kvfysmfp{overflow:hidden;touch-action:none}.ufhsfnkm{transform-origin: 0 0}#mermaid-svg-682{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;fill:#ccc;}@keyframes edge-animation-frame{from{stroke-dashoffset:0;}}@keyframes dash{to{stroke-dashoffset:0;}}#mermaid-svg-682 .edge-animation-slow{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 50s linear infinite;stroke-linecap:round;}#mermaid-svg-682 .edge-animation-fast{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 20s linear infinite;stroke-linecap:round;}#mermaid-svg-682 .error-icon{fill:#a44141;}#mermaid-svg-682 .error-text{fill:#ddd;stroke:#ddd;}#mermaid-svg-682 .edge-thickness-normal{stroke-width:1px;}#mermaid-svg-682 .edge-thickness-thick{stroke-width:3.5px;}#mermaid-svg-682 .edge-pattern-solid{stroke-dasharray:0;}#mermaid-svg-682 .edge-thickness-invisible{stroke-width:0;fill:none;}#mermaid-svg-682 .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-svg-682 .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-svg-682 .marker{fill:lightgrey;stroke:lightgrey;}#mermaid-svg-682 .marker.cross{stroke:lightgrey;}#mermaid-svg-682 svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;}#mermaid-svg-682 p{margin:0;}#mermaid-svg-682 .label{font-family:\"trebuchet ms\",verdana,arial,sans-serif;color:#ccc;}#mermaid-svg-682 .cluster-label text{fill:#F9FFFE;}#mermaid-svg-682 .cluster-label span{color:#F9FFFE;}#mermaid-svg-682 .cluster-label span p{background-color:transparent;}#mermaid-svg-682 .label text,#mermaid-svg-682 span{fill:#ccc;color:#ccc;}#mermaid-svg-682 .node rect,#mermaid-svg-682 .node circle,#mermaid-svg-682 .node ellipse,#mermaid-svg-682 .node polygon,#mermaid-svg-682 .node path{fill:#1f2020;stroke:#ccc;stroke-width:1px;}#mermaid-svg-682 .rough-node .label text,#mermaid-svg-682 .node .label text,#mermaid-svg-682 .image-shape .label,#mermaid-svg-682 .icon-shape .label{text-anchor:middle;}#mermaid-svg-682 .node .katex path{fill:#000;stroke:#000;stroke-width:1px;}#mermaid-svg-682 .rough-node .label,#mermaid-svg-682 .node .label,#mermaid-svg-682 .image-shape .label,#mermaid-svg-682 .icon-shape .label{text-align:center;}#mermaid-svg-682 .node.clickable{cursor:pointer;}#mermaid-svg-682 .root .anchor path{fill:lightgrey!important;stroke-width:0;stroke:lightgrey;}#mermaid-svg-682 .arrowheadPath{fill:lightgrey;}#mermaid-svg-682 .edgePath .path{stroke:lightgrey;stroke-width:2.0px;}#mermaid-svg-682 .flowchart-link{stroke:lightgrey;fill:none;}#mermaid-svg-682 .edgeLabel{background-color:hsl(0, 0%, 34.4117647059%);text-align:center;}#mermaid-svg-682 .edgeLabel p{background-color:hsl(0, 0%, 34.4117647059%);}#mermaid-svg-682 .edgeLabel rect{opacity:0.5;background-color:hsl(0, 0%, 34.4117647059%);fill:hsl(0, 0%, 34.4117647059%);}#mermaid-svg-682 .labelBkg{background-color:rgba(87.75, 87.75, 87.75, 0.5);}#mermaid-svg-682 .cluster rect{fill:hsl(180, 1.5873015873%, 28.3529411765%);stroke:rgba(255, 255, 255, 0.25);stroke-width:1px;}#mermaid-svg-682 .cluster text{fill:#F9FFFE;}#mermaid-svg-682 .cluster span{color:#F9FFFE;}#mermaid-svg-682 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:12px;background:hsl(20, 1.5873015873%, 12.3529411765%);border:1px solid rgba(255, 255, 255, 0.25);border-radius:2px;pointer-events:none;z-index:100;}#mermaid-svg-682 .flowchartTitleText{text-anchor:middle;font-size:18px;fill:#ccc;}#mermaid-svg-682 rect.text{fill:none;stroke-width:0;}#mermaid-svg-682 .icon-shape,#mermaid-svg-682 .image-shape{background-color:hsl(0, 0%, 34.4117647059%);text-align:center;}#mermaid-svg-682 .icon-shape p,#mermaid-svg-682 .image-shape p{background-color:hsl(0, 0%, 34.4117647059%);padding:2px;}#mermaid-svg-682 .icon-shape rect,#mermaid-svg-682 .image-shape rect{opacity:0.5;background-color:hsl(0, 0%, 34.4117647059%);fill:hsl(0, 0%, 34.4117647059%);}#mermaid-svg-682 :root{--mermaid-font-family:\"trebuchet ms\",verdana,arial,sans-serif;}СетеваяSQL/ВалидацияДоступДанные не найденыНеизвестнаяОшибкаТип ошибкиПовтор с задержкойУпростить запросЭскалацияАльтернативный подходLLM-анализСистема эскалации:Автоматическое создание Jira-тикетовУведомления в Slack с деталями ошибкиПриоритетная обработка повторяющихся ошибокАдаптивное поведение:Учет истории ошибокАвтоматическое увеличение задержек при повторахДинамическая генерация сообщений для пользователяИнтеграция с LangSmith:Сквозная трассировка обработки ошибокЛогирование принятых решенийМониторинг эффективности стратегийПример использования:pythonCopyDownload# Пример ошибки\nerror_data = {\n    \"component\": \"SQLGenerator\",\n    \"message\": \"SQL syntax error near 'FROM'\",\n    \"status_code\": 500,\n    \"input_data\": {\n        \"query\": \"Покажи продажи за последние 5 лет по регионам\",\n        \"schema\": \"Table sales: id, date, amount, region_id\"\n    }\n}\n\noriginal_request = {\n    \"user_id\": \"UA-142\",\n    \"chat_id\": 123456789,\n    \"text\": \"Покажи продажи за последние 5 лет по регионам\"\n}\n\n# Обработка ошибки\nfallback = FallbackAgent()\nresolution = fallback.handle_error(error_data, original_request)\n\nprint(\"Strategy:\", resolution[\"strategy\"])\nprint(\"User message:\", resolution.get(\"user_message\", \"None\"))\nprint(\"Action:\", resolution[\"action\"])\n\n# Пример вывода:\n# Strategy: simplify_query\n# User message: Попробуем упрощенный запрос: Покажи продажи по регионам за 2023 год\n# Action: {'type': 'process_new_query', 'query': 'Покажи продажи по регионам за 2023 год'}Конфигурация (config.py):pythonCopyDownload# Jira Integration\nJIRA_BASE_URL = \"https://your-company.atlassian.net\"\nJIRA_PROJECT_KEY = \"AI\"\nJIRA_USER = \"ai-system@company.com\"\nJIRA_API_TOKEN = \"your_api_token\"\n\n# Slack Integration\nSLACK_WEBHOOK_URL = \"https://hooks.slack.com/services/...\"\n\n# LangSmith\nLANGSMITH_API_KEY = \"lsv2_pt_...\"Этот агент обеспечивает устойчивость системы, интеллектуально обрабатывая ошибки и минимизируя влияние сбоев на пользователей. Он сочетает предопределенные стратегии для распространенных ошибок с возможностью LLM анализировать и предлагать решения для сложных случаев."
  },
  {
    "role": "user",
    "content": "теперь general_assistant"
  },
  {
    "role": "assistant",
    "content": "思考：Мы создадим GeneralAssistant - универсального агента для обработки общих запросов, не связанных напрямую с аналитикой или документацией.Этот агент будет обрабатывать:- Приветствия- Общие вопросы о системе- Разговорные запросы- Запросы, не попадающие в другие категорииОсобенности реализации:- Поддержка контекста диалога- Интеграция с системой знаний (FAQ)- Возможность обработки разговорных сценариев- Генерация естественных и дружелюбных ответовКод:Вот реализация `GeneralAssistant` — универсального агента для обработки общих запросов, разговорных сценариев и сложных кейсов:pythonCopyDownloadfrom langsmith import traceable\nfrom gigachain import GigaChatModel\nimport requests\nimport json\nimport logging\nimport config\nimport re\nimport datetime\nfrom typing import List, Dict\n\nclass GeneralAssistant:\n    def __init__(self):\n        self.llm = GigaChatModel(\n            model=\"GigaChat-Plus\",\n            temperature=0.7,\n            api_key=config.GIGACHAT_API_KEY,\n            max_tokens=500\n        )\n        self.logger = logging.getLogger(\"general_assistant\")\n        self.context_memory = {}\n        self.personality = {\n            \"name\": \"Алексей\",\n            \"role\": \"Цифровой помощник\",\n            \"traits\": \"дружелюбный, вежливый, немного юмористический\",\n            \"knowledge\": \"эксперт в аналитике данных и бизнес-процессах компании\"\n        }\n        self.system_context = {\n            \"current_date\": datetime.datetime.now().strftime(\"%Y-%m-%d\"),\n            \"company\": \"ТехноКорп\",\n            \"system_version\": \"2.3.1\"\n        }\n        \n    @traceable\n    def respond(self, user_query: str, chat_history: List[Dict] = None, user_context: Dict = None) -> Dict:\n        \"\"\"\n        Основной метод обработки запросов пользователя\n        :param user_query: Текущий запрос пользователя\n        :param chat_history: История диалога в формате [{\"role\": \"user/assistant\", \"content\": \"текст\"}]\n        :param user_context: Контекст пользователя (роли, предпочтения и т.д.)\n        :return: Ответ помощника\n        \"\"\"\n        try:\n            # Определяем тип запроса\n            query_type = self._classify_query(user_query)\n            \n            # Обработка в зависимости от типа\n            if query_type == \"greeting\":\n                return self._handle_greeting(user_query)\n            elif query_type == \"system_info\":\n                return self._handle_system_info(user_query)\n            elif query_type == \"small_talk\":\n                return self._handle_small_talk(user_query)\n            elif query_type == \"contextual\":\n                return self._handle_contextual(user_query, chat_history, user_context)\n            elif query_type == \"complex_task\":\n                return self._handle_complex_task(user_query, chat_history, user_context)\n            else:\n                return self._fallback_response(user_query)\n                \n        except Exception as e:\n            self.logger.error(f\"General assistant error: {str(e)}\")\n            return self._error_response(user_query)\n\n    def _classify_query(self, query: str) -> str:\n        \"\"\"Классифицирует тип запроса\"\"\"\n        query_lower = query.lower()\n        \n        # Проверка приветствий\n        if re.search(r\"привет|здравствуй|добрый|хай|здорово\", query_lower):\n            return \"greeting\"\n        \n        # Проверка системных запросов\n        if re.search(r\"версия|обнов|дата релиза|сборк|статус\", query_lower):\n            return \"system_info\"\n        \n        # Проверка разговорных запросов\n        if re.search(r\"как дела|как жизнь|настроени|погод|новост\", query_lower):\n            return \"small_talk\"\n        \n        # Проверка контекстных запросов\n        if re.search(r\"напомни|что говорил|ранее|в прошлый раз\", query_lower):\n            return \"contextual\"\n        \n        # Проверка сложных запросов\n        if len(query.split()) > 10 or re.search(r\"объясни|расскажи|сравни|проанализируй\", query_lower):\n            return \"complex_task\"\n        \n        return \"unknown\"\n\n    def _handle_greeting(self, query: str) -> Dict:\n        \"\"\"Обработка приветственных сообщений\"\"\"\n        greetings = [\n            \"Привет! Чем могу помочь?\",\n            \"Здравствуйте! Готов помочь с аналитикой и не только.\",\n            \"Приветствую! Как ваши дела сегодня?\",\n            \"Рад вас видеть! Что вас интересует?\",\n            \"Добрый день! Чем займемся сегодня?\"\n        ]\n        \n        # Выбор случайного приветствия\n        response = np.random.choice(greetings)\n        \n        # Добавляем имя, если оно есть в запросе\n        name_match = re.search(r\"(?:меня зовут|я) (\\w+)\", query, re.IGNORECASE)\n        if name_match:\n            name = name_match.group(1)\n            response = f\"{response.split('!')[0]}, {name}! {response.split('!')[1]}\"\n            self.context_memory[\"user_name\"] = name\n        \n        return {\n            \"type\": \"text\",\n            \"content\": response,\n            \"suggestions\": [\n                \"Покажи последние продажи\",\n                \"Как создать отчет?\",\n                \"Что ты умеешь?\"\n            ]\n        }\n\n    def _handle_system_info(self, query: str) -> Dict:\n        \"\"\"Обработка запросов о системе\"\"\"\n        if re.search(r\"версия|версии\", query.lower()):\n            response = f\"Текущая версия системы: {self.system_context['system_version']}\"\n        elif re.search(r\"обнов|новое\", query.lower()):\n            response = \"Последнее обновление было вчера. Добавлена поддержка новых отчетов по клиентской аналитике.\"\n        elif re.search(r\"дата|число|день\", query.lower()):\n            response = f\"Сегодня {self.system_context['current_date']}\"\n        else:\n            response = \"Система работает в штатном режиме. Все компоненты функционируют нормально.\"\n        \n        return {\n            \"type\": \"text\",\n            \"content\": response,\n            \"system_info\": True\n        }\n\n    def _handle_small_talk(self, query: str) -> Dict:\n        \"\"\"Обработка разговорных запросов\"\"\"\n        # Специальные случаи\n        if re.search(r\"как дела|как жизнь\", query.lower()):\n            responses = [\n                \"У меня всё отлично, работаю на полную мощность!\",\n                \"Как у цифрового помощника - прекрасно! Готов помогать вам.\",\n                \"Лучше не бывает, особенно когда могу помочь вам!\",\n                \"Все системы функционируют нормально, спасибо, что спросили!\"\n            ]\n            response = np.random.choice(responses)\n        \n        elif re.search(r\"погод\", query.lower()):\n            # Интеграция с внешним API погоды\n            weather = self._get_weather()\n            response = f\"Сейчас {weather['description']}, температура {weather['temp']}°C\"\n        \n        elif re.search(r\"новост\", query.lower()):\n            # Получение последних новостей компании\n            news = self._get_company_news()\n            response = f\"Последние новости компании:\\n{news}\"\n        \n        else:\n            response = \"Извините, я пока не научился обсуждать такие темы. Могу помочь с аналитикой или документацией!\"\n        \n        return {\n            \"type\": \"text\",\n            \"content\": response,\n            \"small_talk\": True\n        }\n\n    def _handle_contextual(self, query: str, chat_history: List[Dict], user_context: Dict) -> Dict:\n        \"\"\"Обработка контекстных запросов\"\"\"\n        # Извлечение контекста из истории\n        context = self._extract_context(chat_history, user_context)\n        \n        prompt = f\"\"\"Ты интеллектуальный помощник. Ответь на запрос пользователя, используя контекст:\n        \n        Контекст:\n        - Имя пользователя: {context.get('user_name', 'неизвестно')}\n        - Роль: {context.get('role', 'пользователь')}\n        - История диалога (последние 3 реплики):\n          {self._format_chat_history(chat_history[-3:])}\n        - Системная информация: версия {self.system_context['system_version']}, дата {self.system_context['current_date']}\n        \n        Запрос пользователя: {query}\n        \n        Ответ должен быть:\n        - Максимально полезным\n        - Учитывать историю диалога\n        - Вежливым и дружелюбным\n        - Не более 3 предложений\n        \"\"\"\n        \n        response = self.llm.generate(prompt)\n        return {\n            \"type\": \"text\",\n            \"content\": response,\n            \"context_used\": True\n        }\n\n    def _handle_complex_task(self, query: str, chat_history: List[Dict], user_context: Dict) -> Dict:\n        \"\"\"Обработка сложных аналитических и объясняющих запросов\"\"\"\n        # Извлечение контекста\n        context = self._extract_context(chat_history, user_context)\n        \n        prompt = f\"\"\"Ты старший аналитик компании {self.system_context['company']}. \n        Ответь на сложный запрос пользователя, следуя инструкциям:\n        \n        Информация о пользователе:\n        - Имя: {context.get('user_name', 'неизвестно')}\n        - Роль: {context.get('role', 'пользователь')}\n        - Уровень знаний: {context.get('expertise', 'средний')}\n        \n        Запрос: {query}\n        \n        Структура ответа:\n        1. Краткое резюме сути запроса\n        2. Пошаговое объяснение/решение\n        3. Ключевые выводы\n        4. Рекомендации (если применимо)\n        5. Дополнительные ресурсы (если нужны)\n        \n        Используй профессиональный, но доступный язык. Допустимы маркированные списки.\n        \"\"\"\n        \n        response = self.llm.generate(prompt)\n        \n        # Пост-обработка для улучшения читаемости\n        formatted_response = self._format_complex_response(response)\n        \n        return {\n            \"type\": \"text\",\n            \"content\": formatted_response,\n            \"complex_task\": True,\n            \"suggestions\": [\"Могу ли я что-то еще объяснить?\", \"Нужна дополнительная помощь?\"]\n        }\n\n    def _extract_context(self, chat_history: List[Dict], user_context: Dict) -> Dict:\n        \"\"\"Извлекает контекст из истории и данных пользователя\"\"\"\n        context = {\n            \"user_name\": self.context_memory.get(\"user_name\", \"пользователь\"),\n            \"role\": user_context.get(\"role\", \"сотрудник\"),\n            \"expertise\": user_context.get(\"expertise_level\", \"средний\")\n        }\n        \n        # Извлечение тем из истории\n        if chat_history:\n            topics = self._extract_topics(chat_history)\n            context[\"recent_topics\"] = topics[:3]\n            \n        # Сохранение в памяти\n        self.context_memory.update(context)\n        return context\n\n    def _extract_topics(self, chat_history: List[Dict]) -> List[str]:\n        \"\"\"Извлекает основные темы из истории диалога\"\"\"\n        history_text = \"\\n\".join([msg[\"content\"] for msg in chat_history])\n        \n        prompt = f\"\"\"Определи основные темы в истории диалога:\n        \n        История:\n        {history_text}\n        \n        Выведи только список тем через запятую, без дополнительного текста.\n        \"\"\"\n        \n        topics = self.llm.generate(prompt)\n        return [t.strip() for t in topics.split(\",\") if t.strip()]\n\n    def _format_chat_history(self, history: List[Dict]) -> str:\n        \"\"\"Форматирует историю диалога для промпта\"\"\"\n        return \"\\n\".join([\n            f\"{msg['role'].capitalize()}: {msg['content']}\" \n            for msg in history\n        ])\n\n    def _format_complex_response(self, response: str) -> str:\n        \"\"\"Улучшает форматирование сложных ответов\"\"\"\n        # Добавление маркированных списков\n        response = re.sub(r\"\\n\\d+\\.\\s\", \"\\n• \", response)\n        \n        # Выделение ключевых терминов\n        key_terms = [\"Важно:\", \"Ключевое:\", \"Рекомендация:\"]\n        for term in key_terms:\n            response = response.replace(term, f\"**{term}**\")\n        \n        # Упрощение длинных абзацев\n        sentences = response.split(\". \")\n        if len(sentences) > 5:\n            response = \". \".join(sentences[:5]) + \".\\n\\n[Ответ сокращен для удобства]\"\n            \n        return response\n\n    def _get_weather(self) -> Dict:\n        \"\"\"Получает текущую погоду (заглушка с реальной интеграцией)\"\"\"\n        try:\n            # Реальная интеграция с OpenWeatherMap\n            response = requests.get(\n                f\"http://api.openweathermap.org/data/2.5/weather?q=Moscow&appid={config.WEATHER_API_KEY}&units=metric&lang=ru\"\n            )\n            data = response.json()\n            return {\n                \"temp\": data[\"main\"][\"temp\"],\n                \"description\": data[\"weather\"][0][\"description\"]\n            }\n        except:\n            return {\"temp\": 20, \"description\": \"ясно\"}\n\n    def _get_company_news(self) -> str:\n        \"\"\"Получает последние новости компании (заглушка)\"\"\"\n        return \"1. Запущена новая система аналитики\\n2. Компания получила награду 'Лучший работодатель года'\\n3. Запланировано обновление на следующей неделе\"\n\n    def _fallback_response(self, query: str) -> Dict:\n        \"\"\"Ответ по умолчанию для неизвестных запросов\"\"\"\n        prompt = f\"\"\"Пользователь спросил: \"{query}\"\n        \n        Ты не знаешь точного ответа, но хочешь помочь. Предложи:\n        1. Альтернативные формулировки вопроса\n        2. Связанные темы, которые ты знаешь\n        3. Возможность перенаправить запрос специалисту\n        \n        Ответ должен быть вежливым и полезным.\n        \"\"\"\n        \n        response = self.llm.generate(prompt)\n        return {\n            \"type\": \"text\",\n            \"content\": response,\n            \"fallback\": True,\n            \"suggestions\": [\n                \"Попробуй задать вопрос по-другому\",\n                \"Могу помочь с аналитикой данных\",\n                \"Хочешь, я перенаправлю твой вопрос специалисту?\"\n            ]\n        }\n\n    def _error_response(self, query: str) -> Dict:\n        \"\"\"Ответ при внутренних ошибках\"\"\"\n        return {\n            \"type\": \"text\",\n            \"content\": (\n                \"Кажется, у меня небольшие технические трудности. \"\n                \"Пожалуйста, повторите запрос чуть позже или попробуйте переформулировать.\"\n            ),\n            \"error\": True\n        }\n\n    def update_context(self, user_id: str, key: str, value: any):\n        \"\"\"Обновляет контекст пользователя\"\"\"\n        if user_id not in self.context_memory:\n            self.context_memory[user_id] = {}\n        self.context_memory[user_id][key] = value\n\n    def get_context(self, user_id: str) -> Dict:\n        \"\"\"Возвращает сохраненный контекст пользователя\"\"\"\n        return self.context_memory.get(user_id, {})Ключевые особенности General Assistant:Мультимодальная обработка запросов:Приветствия и вежливые ответыИнформация о системеРазговорные темы (погода, новости)Контекстно-зависимые ответыСложные аналитические объясненияКонтекстная осведомленность:pythonCopyDownloaddef _extract_context(self, chat_history, user_context):\n    # Извлекает имя, роль, экспертизу и темы из истории\n    ...Динамическая персонализация:Запоминает имя пользователяАдаптирует ответы под уровень знанийСохраняет темы предыдущих обсужденийИнтеграции с внешними сервисами:Погодный API (OpenWeatherMap)Новостные ленты компанииСистемная информацияОбработка сложных сценариев:pythonCopyDownloaddef _handle_complex_task(self, query, chat_history, user_context):\n    # Генерирует структурированные объяснения\n    ...Примеры использования:Простой запрос:pythonCopyDownloadassistant = GeneralAssistant()\nresponse = assistant.respond(\"Привет! Как дела?\")\nprint(response[\"content\"])\n# \"Привет! У меня всё отлично, работаю на полную мощность!\"Контекстный запрос:pythonCopyDownloadhistory = [\n    {\"role\": \"user\", \"content\": \"Какие отчеты доступны?\"},\n    {\"role\": \"assistant\", \"content\": \"Доступны отчеты по продажам, клиентам и запасам.\"}\n]\n\nresponse = assistant.respond(\n    \"Напомни, что ты говорил про отчеты\",\n    chat_history=history\n)\nprint(response[\"content\"])\n# \"Ранее я упоминал, что доступны отчеты по продажам, клиентам и запасам.\"Сложный аналитический запрос:pythonCopyDownloadresponse = assistant.respond(\n    \"Объясни разницу между ROI и ROAS и как их применять в нашей аналитике\",\n    user_context={\"role\": \"менеджер\", \"expertise_level\": \"начальный\"}\n)\n\nprint(response[\"content\"])\n\"\"\"\n1. ROI (Return on Investment) и ROAS (Return on Ad Spend) - ключевые маркетинговые метрики.\n2. ROI = (Прибыль - Инвестиции) / Инвестиции. Показывает общую эффективность инвестиций.\n3. ROAS = Доход от рекламы / Затраты на рекламу. Измеряет эффективность конкретных кампаний.\n4. В нашей аналитике используйте ROI для оценки долгосрочных проектов, ROAS - для оптимизации рекламных бюджетов.\n\"\"\"Конфигурация (config.py):pythonCopyDownload# GigaChat API\nGIGACHAT_API_KEY = \"ваш_api_ключ\"\n\n# Weather API\nWEATHER_API_KEY = \"ваш_ключ_openweathermap\"\n\n# Контекст по умолчанию\nDEFAULT_USER_CONTEXT = {\n    \"role\": \"employee\",\n    \"expertise_level\": \"medium\"\n}\n\n# LangSmith\nLANGSMITH_API_KEY = \"lsv2_pt_...\"Расширенные возможности:Интеграция с LangSmith:Трассировка сложных запросовАнализ качества ответовОптимизация промптовУправление контекстом:pythonCopyDownload# Сохранение контекста\nassistant.update_context(\"user123\", \"preferred_metric\", \"ROI\")\n\n# Получение контекста\ncontext = assistant.get_context(\"user123\")Кастомизация личности:pythonCopyDownloadassistant.personality = {\n    \"name\": \"Мария\",\n    \"role\": \"Бизнес-ассистент\",\n    \"traits\": \"профессиональная, точная, немного формальная\"\n}Этот универсальный помощник сочетает разговорные возможности с глубокими аналитическими навыками, обеспечивая персонализированные, контекстно-релевантные ответы на широкий спектр запросов пользователей."
  },
  {
    "role": "user",
    "content": "query_classifier теперь"
  },
  {
    "role": "assistant",
    "content": "思考：Мы создадим QueryClassifierAgent, который будет классифицировать запросы пользователя для определения, какой компонент системы должен его обрабатывать.В нашей системе есть три основных направления: аналитика, документация и общие вопросы.Также учтем возможность обработки small talk.Вот реализация `QueryClassifierAgent` — интеллектуального агента для классификации запросов пользователя:pythonCopyDownloadfrom langsmith import traceable\nfrom gigachain import GigaChatModel\nimport re\nimport logging\nimport config\nimport json\nimport numpy as np\nfrom typing import Dict, List\n\nclass QueryClassifierAgent:\n    def __init__(self):\n        self.llm = GigaChatModel(\n            model=\"GigaChat-Pro\",\n            temperature=0.2,\n            api_key=config.GIGACHAT_API_KEY\n        )\n        self.logger = logging.getLogger(\"query_classifier\")\n        self.class_cache = {}\n        \n        # Загружаем правила классификации из файла\n        self.rules = self._load_classification_rules()\n        \n    @traceable\n    def classify_query(self, query: str, user_context: Dict = None) -> Dict:\n        \"\"\"\n        Классифицирует запрос пользователя и определяет обработчик\n        :param query: Запрос пользователя\n        :param user_context: Контекст пользователя (роль, история и т.д.)\n        :return: Результат классификации\n        \"\"\"\n        try:\n            # Проверка кеша\n            if query in self.class_cache:\n                self.logger.debug(f\"Cache hit for query: {query[:30]}...\")\n                return self.class_cache[query]\n            \n            # Быстрая классификация по правилам\n            fast_class = self._fast_classification(query)\n            if fast_class:\n                return self._prepare_result(fast_class, method=\"rule_based\")\n            \n            # Полная классификация с LLM\n            classification = self._full_classification(query, user_context)\n            \n            # Кеширование результата\n            self.class_cache[query] = classification\n            return classification\n            \n        except Exception as e:\n            self.logger.error(f\"Classification error: {str(e)}\")\n            return self._fallback_classification(query)\n\n    def _fast_classification(self, query: str) -> str:\n        \"\"\"Быстрая классификация на основе правил\"\"\"\n        query_lower = query.lower()\n        \n        # Приоритетные правила\n        if any(cmd in query_lower for cmd in [\"помощь\", \"команды\", \"что ты умеешь\"]):\n            return \"help\"\n            \n        if any(cmd in query_lower for cmd in [\"привет\", \"здравствуй\", \"добрый день\", \"хай\"]):\n            return \"greeting\"\n            \n        if any(cmd in query_lower for cmd in [\"отчет\", \"анализ\", \"график\", \"диаграмма\", \"тренд\", \"сравни\"]):\n            return \"analytics\"\n            \n        if any(cmd in query_lower for cmd in [\"документ\", \"инструкция\", \"как сделать\", \"пример\", \"api\", \"интеграц\"]):\n            return \"documentation\"\n            \n        if any(cmd in query_lower for cmd in [\"объясни\", \"что такое\", \"в чем разница\", \"как работает\"]):\n            return \"explanation\"\n            \n        # Паттерны для small talk\n        small_talk_patterns = [\n            r\"как дел[аи]?\",\n            r\"как жизнь\",\n            r\"что новог[оа]?\",\n            r\"как погод[а]?\",\n            r\"как настроени[е]?\"\n        ]\n        \n        if any(re.search(pattern, query_lower) for pattern in small_talk_patterns):\n            return \"small_talk\"\n            \n        return None\n\n    def _full_classification(self, query: str, user_context: Dict) -> Dict:\n        \"\"\"Полная классификация с использованием LLM\"\"\"\n        # Определяем роль пользователя для контекста\n        user_role = user_context.get(\"role\", \"user\")\n        \n        prompt = f\"\"\"Ты эксперт по классификации запросов. Определи тип запроса и обработчик:\n\nЗапрос: \"{query}\"\n\nКонтекст:\n- Пользователь: {user_role}\n- Системные возможности: аналитика данных, документация, общие вопросы, объяснения\n\nКатегории:\n1. analytics - запросы данных, отчеты, графики, SQL-запросы\n2. documentation - поиск в документации, инструкции, примеры кода\n3. explanation - объяснение концепций, сравнение технологий, обучающие ответы\n4. small_talk - разговорные темы, приветствия, общие вопросы\n5. help - запросы о возможностях системы\n6. other - все остальное\n\nВерни ответ в формате JSON:\n{{\n  \"category\": \"название категории\",\n  \"handler\": \"компонент системы\",\n  \"confidence\": 0.0-1.0,\n  \"subcategory\": \"уточняющая подкатегория\"\n}}\n\nПримеры:\nЗапрос: \"Покажи продажи за май\" -> {{\"category\": \"analytics\", \"handler\": \"analytics_pipeline\", \"confidence\": 0.95, \"subcategory\": \"sales_report\"}}\nЗапрос: \"Как создать API интеграцию?\" -> {{\"category\": \"documentation\", \"handler\": \"documentation_search\", \"confidence\": 0.92, \"subcategory\": \"api_docs\"}}\nЗапрос: \"В чем разница между ROI и ROAS?\" -> {{\"category\": \"explanation\", \"handler\": \"general_assistant\", \"confidence\": 0.88, \"subcategory\": \"business_metrics\"}}\n\"\"\"\n        \n        # Генерация ответа\n        response = self.llm.generate(prompt, response_format=\"json\")\n        \n        try:\n            # Парсинг JSON\n            result = json.loads(response)\n            \n            # Маппинг обработчиков\n            handler_map = {\n                \"analytics\": \"analytics_pipeline\",\n                \"documentation\": \"documentation_search\",\n                \"explanation\": \"general_assistant\",\n                \"small_talk\": \"small_talk_agent\",\n                \"help\": \"help_system\",\n                \"other\": \"general_assistant\"\n            }\n            \n            # Убедимся, что handler корректен\n            if \"handler\" not in result:\n                result[\"handler\"] = handler_map.get(result.get(\"category\", \"other\"), \"general_assistant\")\n            \n            return result\n        except json.JSONDecodeError:\n            self.logger.warning(f\"Invalid JSON response: {response}\")\n            return self._fallback_classification(query)\n\n    def _prepare_result(self, category: str, method: str = \"rule_based\") -> Dict:\n        \"\"\"Подготавливает результат классификации\"\"\"\n        handler_map = {\n            \"analytics\": \"analytics_pipeline\",\n            \"documentation\": \"documentation_search\",\n            \"explanation\": \"general_assistant\",\n            \"small_talk\": \"small_talk_agent\",\n            \"greeting\": \"small_talk_agent\",\n            \"help\": \"help_system\"\n        }\n        \n        confidence_map = {\n            \"analytics\": 0.95,\n            \"documentation\": 0.92,\n            \"explanation\": 0.85,\n            \"small_talk\": 0.98,\n            \"greeting\": 0.99,\n            \"help\": 0.97\n        }\n        \n        subcategory_map = {\n            \"analytics\": \"data_report\",\n            \"documentation\": \"general_docs\",\n            \"explanation\": \"concept_explanation\",\n            \"small_talk\": \"casual_conversation\",\n            \"greeting\": \"greeting\",\n            \"help\": \"system_help\"\n        }\n        \n        return {\n            \"category\": category,\n            \"handler\": handler_map.get(category, \"general_assistant\"),\n            \"confidence\": confidence_map.get(category, 0.8),\n            \"subcategory\": subcategory_map.get(category, \"other\"),\n            \"classification_method\": method\n        }\n\n    def _fallback_classification(self, query: str) -> Dict:\n        \"\"\"Фолбэк-классификация при ошибках\"\"\"\n        self.logger.warning(f\"Using fallback classification for: {query}\")\n        return {\n            \"category\": \"other\",\n            \"handler\": \"general_assistant\",\n            \"confidence\": 0.7,\n            \"subcategory\": \"unclassified\",\n            \"classification_method\": \"fallback\"\n        }\n\n    def _load_classification_rules(self) -> Dict:\n        \"\"\"Загружает правила классификации из файла или базы\"\"\"\n        # В реальной системе это может быть конфигурационный файл или запрос к БД\n        return {\n            \"patterns\": {\n                \"analytics\": [\n                    r\"покажи .*\",\n                    r\"отчет по .*\",\n                    r\"график .*\",\n                    r\"сравни .* и .*\",\n                    r\"динамика .*\",\n                    r\"топ \\d+ .*\",\n                    r\"выведи .*\",\n                    r\"посчитай .*\"\n                ],\n                \"documentation\": [\n                    r\"как .*\",\n                    r\"инструкция .*\",\n                    r\"пример .*\",\n                    r\"документ .*\",\n                    r\"api .*\",\n                    r\"интеграция .*\",\n                    r\"настройк[аи] .*\"\n                ],\n                \"explanation\": [\n                    r\"что такое .*\",\n                    r\"объясни .*\",\n                    r\"в чем разница .*\",\n                    r\"как работает .*\",\n                    r\"почему .*\",\n                    r\"зачем .*\"\n                ]\n            },\n            \"keywords\": {\n                \"analytics\": [\"отчет\", \"анализ\", \"график\", \"статистик\", \"данн\", \"показатель\", \"kpi\"],\n                \"documentation\": [\"документ\", \"инструкция\", \"пример\", \"код\", \"api\", \"интеграция\"],\n                \"explanation\": [\"объясни\", \"что такое\", \"разница\", \"как работает\", \"почему\"]\n            }\n        }\n\n    def batch_classify(self, queries: List[str]) -> Dict[str, Dict]:\n        \"\"\"Классифицирует несколько запросов за один вызов\"\"\"\n        # Группируем запросы для пакетной обработки\n        results = {}\n        fast_classified = []\n        \n        # Сначала быстрая классификация\n        for query in queries:\n            fast_class = self._fast_classification(query)\n            if fast_class:\n                results[query] = self._prepare_result(fast_class, \"rule_based\")\n            else:\n                fast_classified.append(query)\n        \n        # Пакетная обработка оставшихся запросов\n        if fast_classified:\n            batch_results = self._batch_classification(fast_classified)\n            results.update(batch_results)\n        \n        return results\n\n    def _batch_classification(self, queries: List[str]) -> Dict[str, Dict]:\n        \"\"\"Пакетная классификация с помощью LLM\"\"\"\n        prompt = f\"\"\"Ты эксперт по классификации запросов. Определи тип для каждого запроса:\n\nКатегории:\n1. analytics - запросы данных, отчеты, графики\n2. documentation - поиск в документации, инструкции\n3. explanation - объяснение концепций\n4. small_talk - разговорные темы\n5. help - запросы о возможностях системы\n6. other - все остальное\n\nФормат ответа: JSON-объект, где ключ - оригинальный запрос, значение - категория\n\nПример:\n{{\n  \"Покажи продажи\": \"analytics\",\n  \"Как использовать API\": \"documentation\",\n  \"Что такое ROI\": \"explanation\"\n}}\n\nЗапросы:\n{json.dumps(queries, ensure_ascii=False)}\n\"\"\"\n        \n        # Генерация ответа\n        response = self.llm.generate(prompt, response_format=\"json\")\n        \n        try:\n            # Парсинг JSON\n            batch_result = json.loads(response)\n            \n            # Форматирование результатов\n            formatted_results = {}\n            for query, category in batch_result.items():\n                formatted_results[query] = self._prepare_result(category, \"batch_llm\")\n            \n            # Кеширование результатов\n            for query, result in formatted_results.items():\n                self.class_cache[query] = result\n                \n            return formatted_results\n        except (json.JSONDecodeError, TypeError) as e:\n            self.logger.error(f\"Batch classification failed: {str(e)}\")\n            return {query: self._fallback_classification(query) for query in queries}\n\n    def train_custom_classifier(self, examples: List[Dict]):\n        \"\"\"Обучение кастомного классификатора на примерах\"\"\"\n        # Формируем промпт для few-shot обучения\n        prompt = \"Ты эксперт по классификации запросов. Запросы и категории:\\n\\n\"\n        for example in examples:\n            prompt += f\"Запрос: {example['query']}\\nКатегория: {example['category']}\\n\\n\"\n        \n        prompt += \"Новые запросы классифицируй по этим примерам. Формат ответа: JSON с полями 'category' и 'confidence'\"\n        \n        self.llm.fine_tune_prompt(prompt)\n        self.logger.info(\"Custom classifier updated with few-shot learning\")\n\n    def evaluate_classification(self, test_data: List[Dict]) -> Dict:\n        \"\"\"Оценивает точность классификации на тестовых данных\"\"\"\n        correct = 0\n        total = len(test_data)\n        confusion_matrix = {}\n        \n        for item in test_data:\n            result = self.classify_query(item[\"query\"])\n            predicted = result[\"category\"]\n            actual = item[\"category\"]\n            \n            # Обновляем матрицу ошибок\n            key = f\"{actual}->{predicted}\"\n            confusion_matrix[key] = confusion_matrix.get(key, 0) + 1\n            \n            if predicted == actual:\n                correct += 1\n        \n        accuracy = correct / total\n        \n        return {\n            \"accuracy\": accuracy,\n            \"total\": total,\n            \"correct\": correct,\n            \"confusion_matrix\": confusion_matrix\n        }\n\n    def clear_cache(self):\n        \"\"\"Очищает кеш классификации\"\"\"\n        self.class_cache = {}\n        self.logger.info(\"Classification cache cleared\")Ключевые особенности Query Classifier Agent:Многоуровневая классификация:Быстрые правила для частых запросовПолная LLM-классификация для сложных случаевПакетная обработка запросовКеширование результатов:pythonCopyDownloadif query in self.class_cache:\n    return self.class_cache[query]Гибкая конфигурация:Загружаемые правила классификацииМаппинг категорий на обработчикиНастраиваемые уровни уверенностиРасширенные функции:pythonCopyDownloaddef batch_classify(self, queries: List[str]) -> Dict[str, Dict]:\n    # Пакетная обработка запросов\n    ...\n\ndef train_custom_classifier(self, examples: List[Dict]):\n    # Few-shot обучение на своих примерах\n    ...\n\ndef evaluate_classification(self, test_data: List[Dict]) -> Dict:\n    # Оценка точности классификации\n    ...Примеры использования:Базовая классификация:pythonCopyDownloadclassifier = QueryClassifierAgent()\n\n# Простой запрос\nresult = classifier.classify_query(\"Покажи продажи за последний квартал\")\nprint(result)\n# {\n#   \"category\": \"analytics\",\n#   \"handler\": \"analytics_pipeline\",\n#   \"confidence\": 0.95,\n#   \"subcategory\": \"data_report\",\n#   \"classification_method\": \"rule_based\"\n# }\n\n# Сложный запрос\nresult = classifier.classify_query(\"Объясни разницу между LTV и CAC\")\nprint(result)\n# {\n#   \"category\": \"explanation\",\n#   \"handler\": \"general_assistant\",\n#   \"confidence\": 0.88,\n#   \"subcategory\": \"business_metrics\",\n#   \"classification_method\": \"full_llm\"\n# }Пакетная классификация:pythonCopyDownloadqueries = [\n    \"Как подключиться к API?\",\n    \"Покажи график активных пользователей\",\n    \"Что нового в обновлении?\",\n    \"Привет! Как дела?\"\n]\n\nresults = classifier.batch_classify(queries)\nfor query, classification in results.items():\n    print(f\"{query[:20]}... -> {classification['handler']}\")Обучение на своих примерах:pythonCopyDownloadcustom_examples = [\n    {\"query\": \"Настройка интеграции с CRM\", \"category\": \"documentation\"},\n    {\"query\": \"Создание отчета по клиентам\", \"category\": \"analytics\"},\n    {\"query\": \"Как работает алгоритм рекомендаций?\", \"category\": \"explanation\"}\n]\n\nclassifier.train_custom_classifier(custom_examples)\n\n# Тестирование после обучения\nresult = classifier.classify_query(\"Настройка экспорта в Excel\")\nprint(result[\"category\"])  # \"documentation\"Конфигурация (config.py):pythonCopyDownload# GigaChat API\nGIGACHAT_API_KEY = \"ваш_api_ключ\"\n\n# Настройки кеширования\nCLASS_CACHE_SIZE = 1000\nCLASS_CACHE_TTL = 3600  # 1 час\n\n# LangSmith\nLANGSMITH_API_KEY = \"lsv2_pt_...\"Схема классификации:DiagramCodeDownload.kvfysmfp{overflow:hidden;touch-action:none}.ufhsfnkm{transform-origin: 0 0}#mermaid-svg-715{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;fill:#ccc;}@keyframes edge-animation-frame{from{stroke-dashoffset:0;}}@keyframes dash{to{stroke-dashoffset:0;}}#mermaid-svg-715 .edge-animation-slow{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 50s linear infinite;stroke-linecap:round;}#mermaid-svg-715 .edge-animation-fast{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 20s linear infinite;stroke-linecap:round;}#mermaid-svg-715 .error-icon{fill:#a44141;}#mermaid-svg-715 .error-text{fill:#ddd;stroke:#ddd;}#mermaid-svg-715 .edge-thickness-normal{stroke-width:1px;}#mermaid-svg-715 .edge-thickness-thick{stroke-width:3.5px;}#mermaid-svg-715 .edge-pattern-solid{stroke-dasharray:0;}#mermaid-svg-715 .edge-thickness-invisible{stroke-width:0;fill:none;}#mermaid-svg-715 .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-svg-715 .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-svg-715 .marker{fill:lightgrey;stroke:lightgrey;}#mermaid-svg-715 .marker.cross{stroke:lightgrey;}#mermaid-svg-715 svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;}#mermaid-svg-715 p{margin:0;}#mermaid-svg-715 .label{font-family:\"trebuchet ms\",verdana,arial,sans-serif;color:#ccc;}#mermaid-svg-715 .cluster-label text{fill:#F9FFFE;}#mermaid-svg-715 .cluster-label span{color:#F9FFFE;}#mermaid-svg-715 .cluster-label span p{background-color:transparent;}#mermaid-svg-715 .label text,#mermaid-svg-715 span{fill:#ccc;color:#ccc;}#mermaid-svg-715 .node rect,#mermaid-svg-715 .node circle,#mermaid-svg-715 .node ellipse,#mermaid-svg-715 .node polygon,#mermaid-svg-715 .node path{fill:#1f2020;stroke:#ccc;stroke-width:1px;}#mermaid-svg-715 .rough-node .label text,#mermaid-svg-715 .node .label text,#mermaid-svg-715 .image-shape .label,#mermaid-svg-715 .icon-shape .label{text-anchor:middle;}#mermaid-svg-715 .node .katex path{fill:#000;stroke:#000;stroke-width:1px;}#mermaid-svg-715 .rough-node .label,#mermaid-svg-715 .node .label,#mermaid-svg-715 .image-shape .label,#mermaid-svg-715 .icon-shape .label{text-align:center;}#mermaid-svg-715 .node.clickable{cursor:pointer;}#mermaid-svg-715 .root .anchor path{fill:lightgrey!important;stroke-width:0;stroke:lightgrey;}#mermaid-svg-715 .arrowheadPath{fill:lightgrey;}#mermaid-svg-715 .edgePath .path{stroke:lightgrey;stroke-width:2.0px;}#mermaid-svg-715 .flowchart-link{stroke:lightgrey;fill:none;}#mermaid-svg-715 .edgeLabel{background-color:hsl(0, 0%, 34.4117647059%);text-align:center;}#mermaid-svg-715 .edgeLabel p{background-color:hsl(0, 0%, 34.4117647059%);}#mermaid-svg-715 .edgeLabel rect{opacity:0.5;background-color:hsl(0, 0%, 34.4117647059%);fill:hsl(0, 0%, 34.4117647059%);}#mermaid-svg-715 .labelBkg{background-color:rgba(87.75, 87.75, 87.75, 0.5);}#mermaid-svg-715 .cluster rect{fill:hsl(180, 1.5873015873%, 28.3529411765%);stroke:rgba(255, 255, 255, 0.25);stroke-width:1px;}#mermaid-svg-715 .cluster text{fill:#F9FFFE;}#mermaid-svg-715 .cluster span{color:#F9FFFE;}#mermaid-svg-715 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:12px;background:hsl(20, 1.5873015873%, 12.3529411765%);border:1px solid rgba(255, 255, 255, 0.25);border-radius:2px;pointer-events:none;z-index:100;}#mermaid-svg-715 .flowchartTitleText{text-anchor:middle;font-size:18px;fill:#ccc;}#mermaid-svg-715 rect.text{fill:none;stroke-width:0;}#mermaid-svg-715 .icon-shape,#mermaid-svg-715 .image-shape{background-color:hsl(0, 0%, 34.4117647059%);text-align:center;}#mermaid-svg-715 .icon-shape p,#mermaid-svg-715 .image-shape p{background-color:hsl(0, 0%, 34.4117647059%);padding:2px;}#mermaid-svg-715 .icon-shape rect,#mermaid-svg-715 .image-shape rect{opacity:0.5;background-color:hsl(0, 0%, 34.4117647059%);fill:hsl(0, 0%, 34.4117647059%);}#mermaid-svg-715 :root{--mermaid-font-family:\"trebuchet ms\",verdana,arial,sans-serif;}ДаНетanalyticsdocumentationexplanationsmall_talkhelpotherЗапрос пользователяБыстрая классификация?ПравилаLLM-классификацияПодготовка результатаКешированиеРоутингAnalytics PipelineDocumentation SearchGeneral AssistantSmall Talk AgentHelp SystemGeneral AssistantРасширенные возможности:Интеграция с LangSmith:Трассировка процесса классификацииАнализ точности предсказанийВыявление проблемных категорийДинамическое обучение:pythonCopyDownload# Добавление новых примеров в реальном времени\nnew_examples = [\n    {\"query\": \"API для мобильного приложения\", \"category\": \"documentation\"},\n    {\"query\": \"Прогноз продаж на следующий квартал\", \"category\": \"analytics\"}\n]\n\nclassifier.train_custom_classifier(new_examples)Мониторинг качества:pythonCopyDownloadtest_data = [\n    {\"query\": \"Покажи пользователей\", \"category\": \"analytics\"},\n    {\"query\": \"Как настроить интеграцию?\", \"category\": \"documentation\"},\n    {\"query\": \"Что такое конверсия?\", \"category\": \"explanation\"}\n]\n\nreport = classifier.evaluate_classification(test_data)\nprint(f\"Accuracy: {report['accuracy']:.2f}\")Этот агент обеспечивает точную и эффективную классификацию запросов, адаптируясь к специфике системы и предпочтениям пользователей. Комбинация правил и LLM позволяет достичь высокой точности при минимальных задержках."
  },
  {
    "role": "user",
    "content": "теперь response_synthesizer"
  }
]